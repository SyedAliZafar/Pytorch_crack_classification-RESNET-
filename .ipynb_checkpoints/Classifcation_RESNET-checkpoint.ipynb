{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"download_data\">Download Data</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset and unzip the files in your data directory, unlike the other labs, all the data will be deleted after you close  the lab, this may take some time:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q Positive_tensors.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## another method for extarction and unziping the files\n",
    "import wget\n",
    "from zipfile import ZipFile\n",
    "# For postive images\n",
    "# Step 1 \n",
    "url = 'https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip'\n",
    "filename = wget.download(url)\n",
    "\n",
    "# Step 2\n",
    "\n",
    "with ZipFile('resources/Positive_tensors.zip', 'r') as zipObj:\n",
    "   # Extract all the contents of zip file in current directory\n",
    "   zipObj.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For negative images\n",
    "# Step 1\n",
    "url = 'https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip'\n",
    "filename = wget.download(url)\n",
    "print(filename)\n",
    "\n",
    "# Step 2\n",
    "with ZipFile('resources/Negative_tensors.zip', 'r') as zipObj:\n",
    "   # Extract all the contents of zip file in current directory\n",
    "   zipObj.extractall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
    "!unzip -q Negative_tensors.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will install torchvision:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x196e45c08f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the libraries will be used for this lab.\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import pandas\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import torch \n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "import os\n",
    "import glob\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"data_class\">Dataset Class</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset class is essentially the same dataset you build in the previous section, but to speed things up, we are going to use tensors instead of jpeg images. Therefor for each iteration, you will skip the reshape step, conversion step to tensors and normalization step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Create your own dataset object\n",
    "\n",
    "class Dataset(Dataset):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self,transform=None,train=True):\n",
    "        directory = r\"D:\\Image_processing\\AI_VGG_Crack\\Project\\resources\" \n",
    "        positive = \"Positive_tensors\"\n",
    "        negative = \"Negative_tensors\"\n",
    "\n",
    "        positive_file_path=os.path.join(directory,positive)\n",
    "        negative_file_path=os.path.join(directory,negative)\n",
    "        positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n",
    "        negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n",
    "        number_of_samples=len(positive_files)+len(negative_files)\n",
    "        self.all_files=[None]*number_of_samples\n",
    "        self.all_files[::2]=positive_files\n",
    "        self.all_files[1::2]=negative_files \n",
    "        # The transform is goint to be used on image\n",
    "        self.transform = transform\n",
    "        #torch.LongTensor\n",
    "        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
    "        self.Y[::2]=1\n",
    "        self.Y[1::2]=0\n",
    "        \n",
    "        if train:\n",
    "            self.all_files=self.all_files[0:30000]\n",
    "            self.Y=self.Y[0:30000]\n",
    "            self.len=len(self.all_files)\n",
    "        else:\n",
    "            self.all_files=self.all_files[30000:]\n",
    "            self.Y=self.Y[30000:]\n",
    "            self.len=len(self.all_files)     \n",
    "       \n",
    "    # Get the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, idx):\n",
    "               \n",
    "        image=torch.load(self.all_files[idx])\n",
    "        y=self.Y[idx]\n",
    "                  \n",
    "        # If there is any transform method, apply it onto the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train=True)\n",
    "validation_dataset = Dataset(train=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Prepare a pre-trained resnet18 model :</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the pre-trained model resnet18\n",
    "\n",
    "# Type your code here\n",
    "\n",
    "import torchvision.models as model_res\n",
    "\n",
    "\n",
    "model= model_res.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: Set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Set the parameter cannot be trained for the pre-trained model\n",
    "\n",
    "\n",
    "# Type your code here\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 512\n",
    "out = 2\n",
    "model.fc = nn.Linear(hidden, out)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the model in order to show whether you get the correct answer.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_2\">Question 2: Train the Model</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Create a cross entropy criterion function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the loss function\n",
    "\n",
    "# Type your code here\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: Create a training loader and validation loader object, the batch size should have 100 samples each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 3</b>: Use the following optimizer to minimize the loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([parameters  for parameters in model.parameters() if parameters.requires_grad],lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Epoch#1\n",
      "Finished in 1.60145902633667 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#2\n",
      "Finished in 3.241001844406128 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#3\n",
      "Finished in 4.823907852172852 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#4\n",
      "Finished in 6.43317985534668 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#5\n",
      "Finished in 8.088347434997559 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#6\n",
      "Finished in 9.794293403625488 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#7\n",
      "Finished in 11.482661724090576 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#8\n",
      "Finished in 13.160994052886963 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#9\n",
      "Finished in 14.814208507537842 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#10\n",
      "Finished in 16.51529884338379 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#11\n",
      "Finished in 18.235892295837402 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#12\n",
      "Finished in 19.983827114105225 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#13\n",
      "Finished in 21.738597869873047 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#14\n",
      "Finished in 23.47676730155945 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#15\n",
      "Finished in 25.241303205490112 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#16\n",
      "Finished in 27.005838871002197 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#17\n",
      "Finished in 28.738149404525757 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#18\n",
      "Finished in 30.487061023712158 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#19\n",
      "Finished in 32.21448993682861 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#20\n",
      "Finished in 33.94191837310791 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#21\n",
      "Finished in 35.664464235305786 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#22\n",
      "Finished in 37.391892194747925 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#23\n",
      "Finished in 39.10662651062012 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#24\n",
      "Finished in 40.86042070388794 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#25\n",
      "Finished in 42.579060792922974 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#26\n",
      "Finished in 44.29235625267029 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#27\n",
      "Finished in 45.99927830696106 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#28\n",
      "Finished in 47.78822684288025 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#29\n",
      "Finished in 49.53570055961609 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#30\n",
      "Finished in 51.23285722732544 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#31\n",
      "Finished in 52.89388370513916 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#32\n",
      "Finished in 54.62131190299988 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#33\n",
      "Finished in 56.36339020729065 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#34\n",
      "Finished in 58.08984017372131 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#35\n",
      "Finished in 59.8670699596405 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#36\n",
      "Finished in 61.580827474594116 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#37\n",
      "Finished in 63.27017307281494 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#38\n",
      "Finished in 64.98978924751282 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#39\n",
      "Finished in 66.75139546394348 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#40\n",
      "Finished in 68.47491931915283 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#41\n",
      "Finished in 70.16044473648071 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#42\n",
      "Finished in 71.93670129776001 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#43\n",
      "Finished in 73.64850282669067 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#44\n",
      "Finished in 75.41401481628418 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#45\n",
      "Finished in 77.14925527572632 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#46\n",
      "Finished in 78.90988492965698 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#47\n",
      "Finished in 80.659841299057 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#48\n",
      "Finished in 82.42691707611084 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#49\n",
      "Finished in 84.15922856330872 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#50\n",
      "Finished in 85.8505265712738 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#51\n",
      "Finished in 87.57502579689026 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#52\n",
      "Finished in 89.28292393684387 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#53\n",
      "Finished in 91.04843592643738 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#54\n",
      "Finished in 92.8051598072052 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#55\n",
      "Finished in 94.55602407455444 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#56\n",
      "Finished in 96.26392269134521 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#57\n",
      "Finished in 97.97698378562927 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#58\n",
      "Finished in 99.70050597190857 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#59\n",
      "Finished in 101.41035723686218 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#60\n",
      "Finished in 103.16415166854858 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#61\n",
      "Finished in 104.89646244049072 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#62\n",
      "Finished in 106.72743964195251 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#63\n",
      "Finished in 108.50466918945312 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#64\n",
      "Finished in 110.28087520599365 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#65\n",
      "Finished in 112.03271555900574 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#66\n",
      "Finished in 113.84900569915771 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#67\n",
      "Finished in 115.64208626747131 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#68\n",
      "Finished in 117.43981957435608 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#69\n",
      "Finished in 119.272714138031 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#70\n",
      "Finished in 121.06654024124146 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#71\n",
      "Finished in 122.9326319694519 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#72\n",
      "Finished in 124.69033169746399 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#73\n",
      "Finished in 126.50271558761597 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#74\n",
      "Finished in 128.28482866287231 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#75\n",
      "Finished in 130.0767059326172 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#76\n",
      "Finished in 131.8597948551178 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#77\n",
      "Finished in 133.61163592338562 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#78\n",
      "Finished in 135.38593649864197 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#79\n",
      "Finished in 137.16121315956116 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#80\n",
      "Finished in 138.9775035381317 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#81\n",
      "Finished in 140.79919981956482 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#82\n",
      "Finished in 142.57057070732117 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#83\n",
      "Finished in 144.37416625022888 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#84\n",
      "Finished in 146.14456129074097 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#85\n",
      "Finished in 147.90519070625305 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#86\n",
      "Finished in 149.70488023757935 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#87\n",
      "Finished in 151.49968671798706 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#88\n",
      "Finished in 153.2788701057434 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#89\n",
      "Finished in 155.08637189865112 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#90\n",
      "Finished in 156.8483898639679 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#91\n",
      "Finished in 158.65256881713867 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#92\n",
      "Finished in 160.53233122825623 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#93\n",
      "Finished in 162.30760979652405 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#94\n",
      "Finished in 164.1219449043274 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#95\n",
      "Finished in 165.9085922241211 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#96\n",
      "Finished in 167.72488141059875 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#97\n",
      "Finished in 169.49142456054688 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#98\n",
      "Finished in 171.29599690437317 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#99\n",
      "Finished in 173.06541466712952 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#100\n",
      "Finished in 174.8338565826416 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#101\n",
      "Finished in 176.5964388847351 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#102\n",
      "Finished in 178.35609197616577 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#103\n",
      "Finished in 180.09816813468933 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#104\n",
      "Finished in 181.8168079853058 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#105\n",
      "Finished in 183.53056502342224 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#106\n",
      "Finished in 185.25604104995728 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#107\n",
      "Finished in 187.02448201179504 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#108\n",
      "Finished in 188.7567937374115 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#109\n",
      "Finished in 190.56423354148865 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#110\n",
      "Finished in 192.322571516037 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#111\n",
      "Finished in 194.07580518722534 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#112\n",
      "Finished in 195.80225729942322 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#113\n",
      "Finished in 197.54133772850037 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#114\n",
      "Finished in 199.28439021110535 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#115\n",
      "Finished in 201.06943273544312 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#116\n",
      "Finished in 202.91794610023499 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#117\n",
      "Finished in 204.70201206207275 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#118\n",
      "Finished in 206.50715351104736 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#119\n",
      "Finished in 208.26680707931519 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#120\n",
      "Finished in 209.99911785125732 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#121\n",
      "Finished in 211.750958442688 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#122\n",
      "Finished in 213.44811582565308 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#123\n",
      "Finished in 215.21558094024658 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#124\n",
      "Finished in 217.00550508499146 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#125\n",
      "Finished in 218.813006401062 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 220.625390291214 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#127\n",
      "Finished in 222.39480829238892 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#128\n",
      "Finished in 224.165203332901 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#129\n",
      "Finished in 225.8936083316803 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#130\n",
      "Finished in 227.62103652954102 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#131\n",
      "Finished in 229.38948106765747 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#132\n",
      "Finished in 231.16866087913513 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#133\n",
      "Finished in 232.97030353546143 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#134\n",
      "Finished in 234.77176117897034 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#135\n",
      "Finished in 236.51297736167908 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#136\n",
      "Finished in 238.21657991409302 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#137\n",
      "Finished in 240.0172414779663 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#138\n",
      "Finished in 241.83743739128113 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#139\n",
      "Finished in 243.55900692939758 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#140\n",
      "Finished in 245.30036211013794 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#141\n",
      "Finished in 247.05317997932434 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#142\n",
      "Finished in 248.83138632774353 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#143\n",
      "Finished in 250.5968987941742 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#144\n",
      "Finished in 252.3497154712677 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#145\n",
      "Finished in 254.07909655570984 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#146\n",
      "Finished in 255.80554914474487 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#147\n",
      "Finished in 257.5261421203613 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#148\n",
      "Finished in 259.2330639362335 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#149\n",
      "Finished in 260.95951628685 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#150\n",
      "Finished in 262.66058325767517 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#151\n",
      "Finished in 264.39288997650146 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#152\n",
      "Finished in 266.12715435028076 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#153\n",
      "Finished in 267.9551742076874 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#154\n",
      "Finished in 269.7050497531891 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#155\n",
      "Finished in 271.54610538482666 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#156\n",
      "Finished in 273.2972638607025 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#157\n",
      "Finished in 275.0901174545288 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#158\n",
      "Finished in 276.8556296825409 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#159\n",
      "Finished in 278.61918902397156 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#160\n",
      "Finished in 280.40618419647217 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#161\n",
      "Finished in 282.1629071235657 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#162\n",
      "Finished in 283.9137718677521 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#163\n",
      "Finished in 285.6900255680084 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#164\n",
      "Finished in 287.4716854095459 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#165\n",
      "Finished in 289.22059631347656 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#166\n",
      "Finished in 290.9646260738373 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#167\n",
      "Finished in 292.73697304725647 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#168\n",
      "Finished in 294.48686122894287 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#169\n",
      "Finished in 296.2035481929779 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#170\n",
      "Finished in 297.92218804359436 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#171\n",
      "Finished in 299.6994183063507 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#172\n",
      "Finished in 301.42196393013 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#173\n",
      "Finished in 303.2099356651306 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#174\n",
      "Finished in 305.0719585418701 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#175\n",
      "Finished in 306.8068301677704 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#176\n",
      "Finished in 308.5498824119568 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#177\n",
      "Finished in 310.30269980430603 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#178\n",
      "Finished in 312.044775724411 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#179\n",
      "Finished in 313.8288414478302 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#180\n",
      "Finished in 315.6373200416565 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#181\n",
      "Finished in 317.36572456359863 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#182\n",
      "Finished in 319.10096526145935 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#183\n",
      "Finished in 320.85280561447144 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#184\n",
      "Finished in 322.5792579650879 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#185\n",
      "Finished in 324.3340280056 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#186\n",
      "Finished in 326.0946581363678 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#187\n",
      "Finished in 327.8250160217285 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#188\n",
      "Finished in 329.58116841316223 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#189\n",
      "Finished in 331.3388681411743 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#190\n",
      "Finished in 333.0516493320465 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#191\n",
      "Finished in 334.76155829429626 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#192\n",
      "Finished in 336.47433853149414 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#193\n",
      "Finished in 338.204696893692 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#194\n",
      "Finished in 339.92724323272705 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#195\n",
      "Finished in 341.68787240982056 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#196\n",
      "Finished in 343.42179250717163 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#197\n",
      "Finished in 345.1735870838165 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#198\n",
      "Finished in 346.9976930618286 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#199\n",
      "Finished in 348.79347252845764 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#200\n",
      "Finished in 350.54824662208557 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#201\n",
      "Finished in 352.3576982021332 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#202\n",
      "Finished in 354.26308155059814 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#203\n",
      "Finished in 356.1526072025299 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#204\n",
      "Finished in 357.98464846611023 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#205\n",
      "Finished in 359.69938230514526 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#206\n",
      "Finished in 361.45122361183167 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#207\n",
      "Finished in 363.23138308525085 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#208\n",
      "Finished in 364.97150564193726 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#209\n",
      "Finished in 366.76142978668213 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#210\n",
      "Finished in 368.5826027393341 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#211\n",
      "Finished in 370.37057995796204 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#212\n",
      "Finished in 372.1429216861725 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#213\n",
      "Finished in 373.920152425766 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#214\n",
      "Finished in 375.6700396537781 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#215\n",
      "Finished in 377.42480993270874 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#216\n",
      "Finished in 379.21180534362793 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#217\n",
      "Finished in 380.9773168563843 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#218\n",
      "Finished in 382.78774881362915 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#219\n",
      "Finished in 384.54544830322266 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#220\n",
      "Finished in 386.3090069293976 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#221\n",
      "Finished in 388.07158970832825 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#222\n",
      "Finished in 389.86346793174744 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#223\n",
      "Finished in 391.5928485393524 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#224\n",
      "Finished in 393.33297204971313 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#225\n",
      "Finished in 395.08481454849243 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#226\n",
      "Finished in 396.84641909599304 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#227\n",
      "Finished in 398.5650591850281 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#228\n",
      "Finished in 400.3579132556915 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#229\n",
      "Finished in 402.136118888855 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#230\n",
      "Finished in 403.8591818809509 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#231\n",
      "Finished in 405.6295757293701 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#232\n",
      "Finished in 407.3111090660095 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#233\n",
      "Finished in 409.0238904953003 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#234\n",
      "Finished in 410.81186175346375 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#235\n",
      "Finished in 412.5461256504059 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#236\n",
      "Finished in 414.2413296699524 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#237\n",
      "Finished in 415.963876247406 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#238\n",
      "Finished in 417.7489173412323 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#239\n",
      "Finished in 419.46072244644165 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#240\n",
      "Finished in 421.19108033180237 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#241\n",
      "Finished in 422.9624514579773 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#242\n",
      "Finished in 424.70940947532654 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#243\n",
      "Finished in 426.45148611068726 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#244\n",
      "Finished in 428.2199275493622 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#245\n",
      "Finished in 429.9668860435486 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#246\n",
      "Finished in 431.7206792831421 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#247\n",
      "Finished in 433.45982599258423 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#248\n",
      "Finished in 435.2204554080963 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#249\n",
      "Finished in 436.94593143463135 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 438.6782431602478 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#251\n",
      "Finished in 440.4212956428528 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#252\n",
      "Finished in 442.1770417690277 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#253\n",
      "Finished in 444.00602626800537 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#254\n",
      "Finished in 445.76079630851746 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#255\n",
      "Finished in 447.49603748321533 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#256\n",
      "Finished in 449.2117476463318 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#257\n",
      "Finished in 450.9460115432739 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#258\n",
      "Finished in 452.6675810813904 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#259\n",
      "Finished in 454.4538049697876 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#260\n",
      "Finished in 456.1900215148926 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#261\n",
      "Finished in 457.93020606040955 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#262\n",
      "Finished in 459.74356627464294 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#263\n",
      "Finished in 461.4758765697479 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#264\n",
      "Finished in 463.2550599575043 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#265\n",
      "Finished in 465.0586576461792 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#266\n",
      "Finished in 466.8378384113312 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#267\n",
      "Finished in 468.5682005882263 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#268\n",
      "Finished in 470.28051710128784 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#269\n",
      "Finished in 472.00208616256714 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#270\n",
      "Finished in 473.70803213119507 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#271\n",
      "Finished in 475.50479435920715 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#272\n",
      "Finished in 477.29959869384766 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#273\n",
      "Finished in 479.0348393917084 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#274\n",
      "Finished in 480.76813101768494 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#275\n",
      "Finished in 482.5062973499298 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#276\n",
      "Finished in 484.28255105018616 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#277\n",
      "Finished in 486.0675926208496 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#278\n",
      "Finished in 487.7911148071289 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#279\n",
      "Finished in 489.50291991233826 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#280\n",
      "Finished in 491.2821056842804 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#281\n",
      "Finished in 493.0417551994324 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#282\n",
      "Finished in 494.74770069122314 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#283\n",
      "Finished in 496.51418900489807 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#284\n",
      "Finished in 498.26603055000305 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#285\n",
      "Finished in 500.00615429878235 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#286\n",
      "Finished in 501.73364090919495 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#287\n",
      "Finished in 503.4952473640442 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#288\n",
      "Finished in 505.2949368953705 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#289\n",
      "Finished in 507.0829107761383 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#290\n",
      "Finished in 508.8767385482788 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#291\n",
      "Finished in 510.64127373695374 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#292\n",
      "Finished in 512.3901853561401 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#293\n",
      "Finished in 514.1430025100708 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#294\n",
      "Finished in 515.856760263443 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#295\n",
      "Finished in 517.6066482067108 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#296\n",
      "Finished in 519.3018524646759 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#297\n",
      "Finished in 521.0087747573853 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#298\n",
      "Finished in 522.7801451683044 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#299\n",
      "Finished in 524.5212450027466 (s)\n",
      "**********\n",
      "**********\n",
      "Epoch#300\n",
      "Finished in 526.271133184433 (s)\n",
      "**********\n",
      "Finished in 528.1645665168762 (s)\n",
      "Finished in 530.095458984375 (s)\n",
      "Finished in 532.0994832515717 (s)\n",
      "Finished in 534.070182800293 (s)\n",
      "Finished in 536.0567018985748 (s)\n",
      "Finished in 537.8827567100525 (s)\n",
      "Finished in 539.9358952045441 (s)\n",
      "Finished in 541.8039391040802 (s)\n",
      "Finished in 543.7764692306519 (s)\n",
      "Finished in 545.719703912735 (s)\n",
      "Finished in 547.725435256958 (s)\n",
      "Finished in 549.6960122585297 (s)\n",
      "Finished in 551.7056488990784 (s)\n",
      "Finished in 553.7426278591156 (s)\n",
      "Finished in 555.7464056015015 (s)\n",
      "Finished in 557.6867165565491 (s)\n",
      "Finished in 559.6441328525543 (s)\n",
      "Finished in 561.6443083286285 (s)\n",
      "Finished in 563.6059110164642 (s)\n",
      "Finished in 565.576488494873 (s)\n",
      "Finished in 567.6085851192474 (s)\n",
      "Finished in 569.6074800491333 (s)\n",
      "Finished in 571.6591067314148 (s)\n",
      "Finished in 573.5681643486023 (s)\n",
      "Finished in 575.4977283477783 (s)\n",
      "Finished in 577.545832157135 (s)\n",
      "Finished in 579.5381646156311 (s)\n",
      "Finished in 581.5048408508301 (s)\n",
      "Finished in 583.4353771209717 (s)\n",
      "Finished in 585.4196243286133 (s)\n",
      "Finished in 587.4321911334991 (s)\n",
      "Finished in 589.3803079128265 (s)\n",
      "Finished in 591.310848236084 (s)\n",
      "Finished in 593.3082137107849 (s)\n",
      "Finished in 595.3022284507751 (s)\n",
      "Finished in 597.2854981422424 (s)\n",
      "Finished in 599.2365453243256 (s)\n",
      "Finished in 601.2188405990601 (s)\n",
      "Finished in 603.2510380744934 (s)\n",
      "Finished in 605.2264938354492 (s)\n",
      "Finished in 607.1267628669739 (s)\n",
      "Finished in 609.097339630127 (s)\n",
      "Finished in 610.9976127147675 (s)\n",
      "Finished in 612.9222946166992 (s)\n",
      "Finished in 614.8502261638641 (s)\n",
      "Finished in 616.7573313713074 (s)\n",
      "Finished in 618.7240016460419 (s)\n",
      "Finished in 620.7043442726135 (s)\n",
      "Finished in 622.7104794979095 (s)\n",
      "Finished in 624.6439492702484 (s)\n",
      "Finished in 626.5569131374359 (s)\n",
      "Finished in 628.5304200649261 (s)\n",
      "Finished in 630.5127148628235 (s)\n",
      "Finished in 632.491103887558 (s)\n",
      "Finished in 634.4343433380127 (s)\n",
      "Finished in 636.3941743373871 (s)\n",
      "Finished in 638.3071374893188 (s)\n",
      "Finished in 640.2142426967621 (s)\n",
      "Finished in 642.1662657260895 (s)\n",
      "Finished in 644.1202421188354 (s)\n",
      "Finished in 646.0566415786743 (s)\n",
      "Finished in 648.0487017631531 (s)\n",
      "Finished in 650.024162530899 (s)\n",
      "Finished in 652.044086933136 (s)\n",
      "Finished in 654.0149908065796 (s)\n",
      "Finished in 655.8991930484772 (s)\n",
      "Finished in 657.8512165546417 (s)\n",
      "Finished in 659.8081223964691 (s)\n",
      "Finished in 661.8402190208435 (s)\n",
      "Finished in 663.8059134483337 (s)\n",
      "Finished in 665.7452428340912 (s)\n",
      "Finished in 667.8056573867798 (s)\n",
      "Finished in 669.7878715991974 (s)\n",
      "Finished in 671.768214225769 (s)\n",
      "Finished in 673.7212145328522 (s)\n",
      "Finished in 675.7054674625397 (s)\n",
      "Finished in 677.7033812999725 (s)\n",
      "Finished in 679.7286417484283 (s)\n",
      "Finished in 681.6689493656158 (s)\n",
      "Finished in 683.7205739021301 (s)\n",
      "Finished in 685.6364667415619 (s)\n",
      "Finished in 687.5953259468079 (s)\n",
      "Finished in 689.6368734836578 (s)\n",
      "Finished in 691.6568801403046 (s)\n",
      "Finished in 693.6362457275391 (s)\n",
      "Finished in 695.6035170555115 (s)\n",
      "Finished in 697.6844384670258 (s)\n",
      "Finished in 699.7214171886444 (s)\n",
      "Finished in 701.7906212806702 (s)\n",
      "Finished in 703.8379938602448 (s)\n",
      "Finished in 705.8886432647705 (s)\n",
      "Finished in 707.9432003498077 (s)\n",
      "Finished in 709.9674863815308 (s)\n",
      "Finished in 712.0034878253937 (s)\n",
      "Finished in 713.997499704361 (s)\n",
      "Finished in 716.045220375061 (s)\n",
      "Finished in 718.0343503952026 (s)\n",
      "Finished in 720.0225045681 (s)\n",
      "Finished in 722.0272607803345 (s)\n",
      "Finished in 724.0359194278717 (s)\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "accuracy = 0\n",
    "correct = 0\n",
    "N_test = len(validation_dataset)\n",
    "N_train = len(train_dataset)\n",
    "start_time = time.time()\n",
    "Loss= 0\n",
    "result_txt=[]\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (x, y) in enumerate(train_loader):  \n",
    "        print(\"**********\")\n",
    "        print('Epoch#{}'.format(i+1))\n",
    "        # set model to train \n",
    "        model.train() \n",
    "        \n",
    "        # clear gradient \n",
    "        optimizer.zero_grad()\n",
    "     \n",
    "        # make a prediction \n",
    "        yhat = model(x)\n",
    "   \n",
    "        # calculate loss \n",
    "        loss = criterion(yhat, y) \n",
    "        # loss.requires_grad = True\n",
    "    \n",
    "        # calculate gradients of parameters \n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters \n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_list.append(loss.item())\n",
    "        #print(type(loss_list))\n",
    "        print(\"Finished in {} (s)\".format(time.time()- start_time))\n",
    "        print(\"**********\")\n",
    "    # end for\n",
    "        \n",
    "    correct=0\n",
    "    for i, (x_test, y_test) in enumerate(validation_loader):\n",
    "        i_start_time = time.time()\n",
    "        \n",
    "        \n",
    "        # set model to eval \n",
    "        model.eval()\n",
    "       \n",
    "        # make a prediction \n",
    "        yhat_val = model(x_test)\n",
    "        \n",
    "        # find max \n",
    "        _, yhat_val_max = torch.max(yhat_val.data, 1)\n",
    "       \n",
    "       \n",
    "        #Calculate misclassified  samples in mini-batch \n",
    "        #hint +=(yhat==y_test).sum().item()\n",
    "        correct += (yhat_val_max==y_test).sum().item()  \n",
    "        \n",
    "        print(\"Finished in {} (s)\".format(time.time()-start_time))\n",
    "        \n",
    "\n",
    "\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - accuracy: 0.994\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# end for\n",
    "\n",
    "accuracy=correct/N_test\n",
    "print(\"Epoch %d - accuracy: %.3f\" % (epoch+1, accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Image_processing\\\\AI_VGG_Crack\\\\Project'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# open file in write mode\n",
    "with open(r'resources/losses.txt', 'w') as fp:\n",
    "    for loss in loss_list:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % loss)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loss_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Print out the Accuracy and plot the loss stored in the list <code>loss_list</code> for every iteration and take a screen shot.</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9943"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "with open('resources/losses.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    x = [float(line.split()[0]) for line in lines]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6997299790382385,\n",
       " 0.6645054817199707,\n",
       " 0.6038039922714233,\n",
       " 0.5706762671470642,\n",
       " 0.5744839310646057]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 960x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(12, 5), dpi=80)\n",
    "\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(x)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Find the misclassified samples</h2> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Identify the first four misclassified samples using the validation data:</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 22; Predicted value: tensor([0]); Actual value: tensor([1])\n",
      "Sample: 101; Predicted value: tensor([1]); Actual value: tensor([0])\n",
      "Sample: 182; Predicted value: tensor([0]); Actual value: tensor([1])\n",
      "Sample: 213; Predicted value: tensor([1]); Actual value: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "max_num_of_items = 4  # first four mis-classified samples\n",
    "validation_loader_misclassified = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=1)\n",
    "\n",
    "for i, (x_test, y_test) in enumerate(validation_loader_misclassified):\n",
    "    # set model to eval\n",
    "    model.eval()\n",
    "    \n",
    "    # make a prediction\n",
    "    yhat = model(x_test)\n",
    "    \n",
    "    # find max\n",
    "    _, yhat_max = torch.max(yhat.data, 1)\n",
    "    \n",
    "    # print mis-classified samples\n",
    "    if yhat_max != y_test:\n",
    "        print(\"Sample: {}; Predicted value: {}; Actual value: {}\".format(str(i), str(yhat_max), str(y_test)))\n",
    "        count += 1\n",
    "        if count >= max_num_of_items:\n",
    "            break\n",
    "    # end if\n",
    "# end for   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
